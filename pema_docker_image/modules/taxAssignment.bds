#!/usr/bin/env bds

# Function to run the CREST classifier 
string crestAssign(string{} params, string{} globalVars) {

   if ( params{'custom_ref_db'} != 'Yes') {


      if ( (params{'gene'} == 'gene_16S' || params{'gene'} == 'gene_18S') && params{'taxonomyAssignmentMethod'} != 'phylogeny' ) {

         # string algoCluster1 = params{'clusteringAlgo'}
         # string algo1 = algoCluster1.split('_')[1]
         # string assignmentPath = globalVars{'genePath'} + '/' + params{'gene'} +  '/' + algo1
         # assignmentPath.chdir()
         globalVars{'assignmentPath'}.chdir()


         if ( params{'taxonomyFolderName'}.isDir() ){
            int previousRandomNumber = randInt( 100 )
            sys mv $params{'taxonomyFolderName'} old.$previousRandomNumber.$params{'taxonomyFolderName'}
         }

      
         if ( params{'silvaVersion'} == 'silva_128' ) { 

            # First use megablast algorithm of blastn for sequence identification, intra-species comparison                   
            task $globalVars{'path'}/tools/ncbi-blast-2.8.1+/bin/blastn \
               -task megablast \
               -query all_sequences_grouped.fa \
               -db $globalVars{'path'}/tools/CREST/LCAClassifier/parts/flatdb/silvamod/silvamod128.fasta \
               -num_alignments 100 \
               -outfmt 5 \
               -out mysilvamod128_$params{'taxonomyFolderName'}.xml \
               -num_threads $params{'vsearchThreads'}
            
            wait
            
            # And then use the classifier in order to get our assignment
            task $globalVars{'path'}/tools/CREST/LCAClassifier/bin/classify \
               -t allTab_$params{'taxonomyFolderName'}.tsv \
               -o $params{'taxonomyFolderName'} mysilvamod128_$params{'taxonomyFolderName'}.xml
            
            wait
            
         # Follow the same steps for the case of the Silva 132    
         } else if ( params{'silvaVersion'} == 'silva_132' ) {
               
            task $globalVars{'path'}/tools/ncbi-blast-2.8.1+/bin/blastn \
               -task megablast \
               -query all_sequences_grouped.fa \
               -db $globalVars{'path'}/tools/CREST/LCAClassifier/parts/flatdb/silva132/silva132 \
               -num_alignments 100 \
               -outfmt 5 \
               -out mysilvamod132_$params{'taxonomyFolderName'}.xml \
               -num_threads $params{'vsearchThreads'}
            
            wait
            
            task $globalVars{'path'}/tools/CREST/LCAClassifier/bin/classify \
               -c $globalVars{'path'}/tools/CREST/LCAClassifier/parts/etc/lcaclassifier.conf \
               -d silva132 \
               -t allTab_$params{'taxonomyFolderName'}.tsv \
               -o $params{'taxonomyFolderName'} mysilvamod132_$params{'taxonomyFolderName'}.xml
            
            wait      
         }

         task {
            sys mv $params{'taxonomyFolderName'}/allTab_$params{'taxonomyFolderName'}.tsv $params{'taxonomyFolderName'}/finalTable.tsv
            sys sed -i 's/classification/Classification/g' $params{'taxonomyFolderName'}/finalTable.tsv
         }
         wait


      } else if (params{'gene'}  == 'gene_ITS') {

         globalVars{'assignmentPath'}.chdir()

         task $globalVars{'path'}/tools/ncbi-blast-2.8.1+/bin/blastn -task megablast \
            -query all_sequences_grouped.fa \
            -db $globalVars{'path'}/tools/CREST/LCAClassifier/parts/flatdb/unite/unite.fasta \
            -num_alignments 100 -outfmt 5 \
            -out unite_$params{'taxonomyFolderName'}.xml \
            -num_threads $params{'vsearchThreads'}

         wait
            
         task $globalVars{'path'}/tools/CREST/LCAClassifier/bin/classify \
            -c $globalVars{'path'}/tools/CREST/LCAClassifier/parts/etc/lcaclassifier.conf \
            -d unite \
            -t allTab_$params{'taxonomyFolderName'}.tsv \
            -o $params{'taxonomyFolderName'} unite_$params{'taxonomyFolderName'}.xml
         
         wait
         
         task {
            sys mv $params{'taxonomyFolderName'}/allTab_$params{'taxonomyFolderName'}.tsv $params{'taxonomyFolderName'}/finalTable.tsv
            sys sed -i 's/classification/Classification/g' $params{'taxonomyFolderName'}/finalTable.tsv
         }
         wait
      }

   } else {

      # # That is the case where a custom DB has been asked for the taxonomy step 

      # task java -Xmx64g -jar $globalVars{'path'}/tools/RDPTools/classifier.jar classify -t $globalVars{'path'}/tools/RDPTools/TRAIN/$params{'name_of_custom_db'}/rRNAClassifier.properties -o tax_assign_swarm_COI_temp.txt rdpClassifierInput.fasta

   }

   return 'ok'

}

# Function to get the phylogeny based taxonomy assignmnent in case of the 16S marker gene
string phylogenyAssign(string{} params, string{} globalVars) {

   ## we need a REFERENCE TREE which we generated it from SILVA database with the aid of GAPPA.
   ## we used GAPPA in order to keep only 10.000 taxa from SILVA.
   ## we then used RAXML - NG which it returnerd us our REF TREE - you can find the corresponding script for
   ## getting this tree in  $path/tools/silva_132/for_placement
   ## in order to get our PHYLOGENY based taxonomy assignment we make use of EPA - NG // last version of Evolutionary Placement Algorithm
   
   globalVars{'assignmentPath'}.chdir()
   
   wait
   
   # PaPaRa returns a msa of our queries that has taken into account info from our ref tree 
   task $globalVars{'path'}/tools/PaPaRa/papara_static_x86_64 \
      -t $globalVars{'path'}/tools/createTreeTheEasyWay/raxml_easy_right_refmsa.raxml.bestTree \
      -s $globalVars{'path'}/tools/createTreeTheEasyWay/raxml_easy_right_refmsa.raxml.reduced.phy \
      -q all_sequences_grouped.fa -r #-j 4
   
   wait
   
   # Remove the ref - msa - THIS IS A BUG OF EPA-ng !!!!
   sys tail -n +1038 papara_alignment.default > papara_alignment.phy
   wait

   # Convert our query msa to fasta format with a script we made because epa-ng can handle only fasta
   task bash $globalVars{'path'}/scripts/convertPhylipToFasta.sh  papara_alignment.phy
   
   wait
         
   # Execute epa-ng algorithm (evolutinary placement) in order to get our phylogenetic-based taxonomy assignment, at last!
   task $globalVars{'path'}/tools/EPA-ng/epa/bin/epa-ng \
      -s $globalVars{'path'}/tools/createTreeTheEasyWay/raxml_easy_right_refmsa.raxml.reduced.phy.fasta \
      -t $globalVars{'path'}/tools/createTreeTheEasyWay/raxml_easy_right_refmsa.raxml.bestTree \
      -q papara_alignment.fasta \
      --model GTR{0.959447/2.52497/1.45842/1.06213/3.55143/1}+FU{0.237221/0.230211/0.294337/0.238231}+G4m{0.559838} # -w <output_dir>
   
   wait

   string assignFolder="16S_taxon_assign_phylogeny_assignment"
   assignFolder.mkdir()
   sys mv epa* $assignFolder

   println("Phylogenetic based taxonomy assignemnt has been completed.")

   return 'ok'

}

# Function to build the OTU or the ASV table once the RDP classifier has been used
string rdpBuildingTable(string{} params, string{} globalVars) {

   task {
      sys awk -F "\t" '{print substr($0, index($0,$6)) }' tax_assign_temp.txt > taxonomies_tmp.txt 
      sys sed 's/Kingdom//g ; s/Phylum//g ; s/Class//g ; s/Order/g/ ; s/Family//g ; s/Genus//g ; s/Species//g' taxonomies_tmp.txt > taxonomies.txt
      sys awk '{print $1}' tax_assign_temp.txt > ids.txt
      sys paste ids.txt taxonomies.txt > tax_assignments.tsv
      sys rm ids.txt taxonomies_tmp.txt taxonomies.txt tax_assign_temp.txt
   }

   println('RDPClassifier has ran as it should ')

   wait
   
   # Create a MOTU table as for the case of 16S
   # Change the swarm output as we have removed some amplicons after the ASV inferring because of the chimera removal
   task {
      sys bash $globalVars{'path'}/scripts/makeMotuTableForRDPClassifier.sh
   }

   wait

   return 'ok'
}

# Use the RDP Classifier with a database among Midori 1 and 2 or a custom one. 
string rdpAssign(string{} params, string{} globalVars) {

   println('RDPClassifier is about to start assigning your grouped sequences.')

   globalVars{'assignmentPath'}.chdir()


   if ( params{'custom_ref_db'} != 'Yes' ) {


      if ( params{'gene'} == "gene_COI" ) {

         task java -Xmx64g -jar $globalVars{'path'}/tools/RDPTools/classifier.jar classify -t $globalVars{'path'}/tools/RDPTools/TRAIN/$params{'midori_version'}/rRNAClassifier.properties -o tax_assign_temp.txt all_sequences_grouped.fa

         wait

         rdpBuildingTable(params, globalVars)

         wait

      } else {

         println('You have selected a combination of parameters that Pema does not support.')

      }

   #  A custom db is used
   } else {

      # That is the case where a custom DB has been asked for the taxonomy step 

      task java -Xmx64g -jar $globalVars{'path'}/tools/RDPTools/classifier.jar classify -t $globalVars{'path'}/tools/RDPTools/TRAIN/$params{'name_of_custom_db'}/rRNAClassifier.properties -o tax_assign_temp.txt all_sequences_grouped.fa

      wait

      rdpBuildingTable(params, globalVars)

      wait

   }

   return 'ok'

}










#  In case of RDP, keep high confident assignments 

# string rdpAssignmentsPerSample(){
# string fileFromRdpClassifier
# string textFinal
# string perSampleTriples

# # make as variables the files that will be used and created, depending on the clustering algo
# if (  paramsOfTaxonomy{'gene'} == 'gene_COI'  && paramsOfTaxonomy{'clusteringAlgoForCOI_ITS'} == 'algo_SWARM' ) {
#    string swarmPath = genePath + '/' + 'gene_COI' +  '/' + 'SWARM'
#    fileFromRdpClassifier = 'tax_assign_swarm_COI.txt'
#    textFinal = 'finalTriplesFromSwarmClustering.txt'
#    perSampleTriples = 'finalTriplesPerSampleFromSwarmClustering.txt'
#    swarmPath.chdir()
# } else if ( paramsOfTaxonomy{'gene'} == 'gene_COI'  && paramsOfTaxonomy{'clusteringAlgoForCOI_ITS'} == 'algo_CROP' ) {
#    string croPath = genePath + '/' + 'gene_COI' +  '/' + 'CROP'
#    fileFromRdpClassifier = 'taxonomy_from_rdpclassifer_COI_CROP.txt'
#    textFinal = 'finalTriplesFromCropClustering.txt'
#    perSampleTriples = 'finalTriplesPerSampleFromCropClustering.txt'
#    croPath.chdir()
# }
# wait

# # we check whether the output of the classifier is non-zero
# if (  paramsOfTaxonomy{'gene'} == 'gene_COI'  && fileFromRdpClassifier.size() != 0 ) {
#    print ' we have a RDPClassifier output file to work with!!! '
#    bool debugCode = false
   
#    string{} giveSampleAndTaxonomyGetSizeSum
#    string{} sampleIdentifiers          #set of all samples encountered
#    string{} taxaNames               #set of all assigned taxa
   
# #####   from output file from both SWARM and CROP clustering  algorithms and RDPClassifier afterwards,
# #####   I get an 'assignment.txt' file, from which  i get all the information i need   
# #####   here, i keep only the taxonomy that is from a threshold and above ( e.g >97%) and i merge all otus
# #####   with the same taxonomy in the same sample in one entry
# #####   finally, i sum up the sizes of the otus i merged
   
#    string[] lines = fileFromRdpClassifier.readLines()
#    for ( string line : lines ) {
#    # input file looks like:
#    #ERR1308250:22628;size=4349_TAB__TAB_root_TAB_root_TAB_1Eukaryota   superkingdom   1   Arthropoda   phylum...
#    #0   1   2   3   4   5   6   7   8   9   10...
#    #PARSE   SKIP   SKIP   SKIP   PARSE   PARSE   SKIP   PARSE   PARSE   SKIP...
   
#       print line + "\n"
#       string[] lineElements = line.split("\t")
#       string sample = lineElements[0].split(':')[0]                                 #parse 1st column (index 0), get first component
#       string sizeAsString = lineElements[0].split('=')[1]                              #parse 1st column (index 0), get last component
#       int size = sizeAsString.parseInt()

#       if ( debugCode ) {
#          print "TEST1\t "+ sample + "\t" + size + "\n"
#       }

#       string thereIsMoreToRead = 'true'

#       #current triplet refers to e.g. "Eukaryota   superkingdom   1" columns with index 1,2,3
#       int currentTripletStartColumn = 1                                                 #start parsing now from the 2nd column, ie. with index 1
#       string assigned_taxo=""
#       string assignmentConfidence=0

#       while ( thereIsMoreToRead == 'true' ) {
         
#          assigned_taxo = lineElements[currentTripletStartColumn]                              #read column with index 5, 8, 11...
         
#          if ( debugCode ) {
#             print "t1:" + currentTripletStartColumn + ":" + assigned_taxo + "\n"
#          }

#          #columns with index 6, 9, 12,... are skipped
#          #read column with index 7, 10, 13...
#          assignmentConfidence = lineElements[currentTripletStartColumn + 2]
#          print "the assigned taxo is " + assigned_taxo + "\n"
#          print "assignmentConfidence is " + assignmentConfidence + "\n"
#          print "size is equal to: " + size + "\n"
#          if ( debugCode ) {
#             print "t2:" + currentTripletStartColumn +":" +assignmentConfidence + "\n"
#          }
#          #if no next taxon triple follows return 
#          int nextTripletConfidenceColumn = currentTripletStartColumn + 5 
#          if ( debugCode ) {
#             print "t3:" + currentTripletStartColumn + " index out of max "+ lineElements.size() - 1 +"\n"
#          }
#          #inspect column with index 8, 11, 14... for existence
#          if ( nextTripletConfidenceColumn > lineElements.size() ) { 
#             #the whole table has been read and the species level reached
#             if ( debugCode ) {
#                print "t4: column with index " + nextTripletConfidenceColumn + " does not exist\n"
#             }
#             thereIsMoreToRead = 'false'
#             continue;
#          }
#          #if the confience of the next taxon is below confidence return
#          if ( lineElements[nextTripletConfidenceColumn] < 0.97 ) {
#             if ( debugCode ) {
#                print "t5:" + nextTripletConfidenceColumn + "\n"
#             }
#             thereIsMoreToRead = 'false'
#             continue;
#          }

#          currentTripletStartColumn = currentTripletStartColumn + 3 #move to next taxon triple

#       } #end of while to read taxa and confidence levels
      
#       if ( debugCode ) {
#          print "TEST2\t "+ sample + "\t" + assigned_taxo + "\t" + assignmentConfidence + "\t" + size + "\n"
#       }
   
#    #######################     till here, my code finds the taxon level   ####################################
         
#       sampleIdentifiers { sample } = 1;
#       taxaNames { assigned_taxo } = 1;
      
#       wait
         
#       #sum size to any previous size sum corresponding to SampleAndTaxonomy pair
#       if ( giveSampleAndTaxonomyGetSizeSum.hasKey(sample+'_SEP_'+assigned_taxo ) == 'true') {
#          int newSum = giveSampleAndTaxonomyGetSizeSum { sample+'_SEP_'+assigned_taxo }.parseInt()
#          print("size is " + size)
#          newSum += size
#          print("new sum is " + newSum)
#          giveSampleAndTaxonomyGetSizeSum { sample+'_SEP_'+assigned_taxo } = newSum
#       } else {
#          giveSampleAndTaxonomyGetSizeSum { sample+'_SEP_'+assigned_taxo } =  size
#       }
      
#       if ( debugCode ) {
#          print "TEST3\t"+ sample+'_'+assigned_taxo + "-" + giveSampleAndTaxonomyGetSizeSum{ sample+'_'+assigned_taxo }  +"\n"
#       }
#    } #end of each input file line
   
#    wait
   
#    if ( debugCode ) {
#       print giveSampleAndTaxonomyGetSizeSum
#    }
   
#    #print output based on the giveSampleAndTaxonomyGetSizeSum map
#    string sampleToPrint
#    string sizeSumToPrint
#    string taxonomyToPrint
#    wait
#    for(string sampleAndTaxon : giveSampleAndTaxonomyGetSizeSum.keys() ) {
#       sampleToPrint =  sampleAndTaxon.split('_SEP_')[0]
#       sizeSumToPrint =  giveSampleAndTaxonomyGetSizeSum{ sampleAndTaxon }
#       taxonomyToPrint =  sampleAndTaxon.split('_SEP_')[1]
#       sys echo '$sampleToPrint    $sizeSumToPrint    $taxonomyToPrint ' >>  $textFinal
      
#    }
   
#    if ( debugCode ) {
#       print taxaNames
#       print sampleIdentifiers
#    }
   
#    ## double for-loop with all the sample id and taxa name possible combinations printing the real ones,
#    ## the ones that have a value that is
#    string sizeToPrintPerSample
#    for (string sampleId : sampleIdentifiers.keys()) {
#       for ( string currentTaxon : taxaNames.keys() ){
         
#          ## print only for the sample and taxonomy pairs that have a size
#          if ( giveSampleAndTaxonomyGetSizeSum.hasKey( sampleId+"_SEP_"+currentTaxon)) {
#             sizeToPrintPerSample = giveSampleAndTaxonomyGetSizeSum { sampleId+"_SEP_"+currentTaxon }
#             sys echo '$sampleId   $sizeToPrintPerSample   $currentTaxon' >>  $sampleId.$perSampleTriples
#          }
#       }
#    }
#    print 'i did just find with the tripltes! ' + "\n"
#    wait
   
#    # finaly, make an OTU table only with the significant assignments (>97%)
#    if ( paramsOfTaxonomy{'clusteringAlgoForCOI_ITS'} == 'algo_SWARM' ) {
#       string swarmPath = genePath + '/' + 'gene_COI' +  '/' + 'SWARM'
#       swarmPath.chdir()
#       sys bash $path/scripts/createOtuTableOnlyForTaxonomyAssigned.sh      
#    }
   
#    if ( paramsOfTaxonomy {'clusteringAlgoForCOI_ITS'} == 'algo_CROP') {
#       string cropPath = genePath + '/' + 'gene_COI' +  '/' + 'CROP'
#       cropPath.chdir()
#       sys bash $path/scripts/createOtuTableOnlyForTaxonomyAssigned.sh
#    }

# }

# print ' At last! We now have the MOTU-table! :) ' + "\n"
# wait
# }








